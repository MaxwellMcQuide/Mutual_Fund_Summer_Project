{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: INSTRUCTIONS\n",
    "\n",
    "''' \n",
    "This code gathers Private Holdings for Mutual Funds from Filing Data Links\n",
    "Please Follow the Following Instructions\n",
    "\n",
    "Step 1: Run Cell 2. This Cell will import all necessary python modules to run the script. \n",
    "        It it possible that not all of these modules are installed on your machine. \n",
    "        To install these modules, open the terminal and type \"pip install insert_module_here\". \n",
    "        The pip install commands for each module are printed next to each import\n",
    "\n",
    "        For example, to install BeautifulSoup, open the terminal and enter \"pip install BeautifulSoup4\"ArithmeticError\n",
    "\n",
    "Step 2: Run Cell 3. This will save all of the necessary functions needed to gather filing data.\n",
    "\n",
    "Step 3: Save the the desired list of URLs to the variable \"URL_list.\" \n",
    "        There are 2 methods for doing this\n",
    "\n",
    "        Method 1: Manually enter a list of URLs (Follow Instructions in Cell 4)\n",
    "        Method 2: Load in a list of URLs from a csv file (Follow Instructions in Cell 5)\n",
    "\n",
    "Step 4: Follow Instructions in Cell 6 and then run Cell 6. \n",
    "        This will save and download all holding information to a csv file.\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Imports\n",
    "\n",
    "from bs4 import BeautifulSoup # pip install BeautifulSoup4\n",
    "import requests # pip install requests\n",
    "import pandas as pd # pip install pandas\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "import time \n",
    "from tqdm.notebook import tqdm # pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Functions\n",
    "\n",
    "def Request(URL, Type):\n",
    "    \"\"\"\n",
    "    Function: Get XML or HTML Soup Object\n",
    "\n",
    "    Variables\n",
    "        URL: XML URL\n",
    "        Type: Request Type (XML or HTML)\n",
    "    \"\"\"\n",
    "\n",
    "    error = False # Used for troubleshooting\n",
    "\n",
    "    while True:\n",
    "        request = requests.get(URL, headers={'User-Agent': 'last_name.first_name@outlook.com'})\n",
    "\n",
    "        if request.status_code == 200:\n",
    "            error = False\n",
    "            if Type == 'XML':\n",
    "                soup = BeautifulSoup(request.text, \"xml\")\n",
    "            elif Type == 'HTML':\n",
    "                soup = BeautifulSoup(request.content, 'html.parser')\n",
    "            return soup\n",
    "        \n",
    "        else:\n",
    "            if error == False:\n",
    "                error = True\n",
    "                time.sleep(5) # pause code for 5 seconds to see if request error goes away\n",
    "            elif error == True:\n",
    "                print(f\"Received unexpected status code {request.status_code}\")\n",
    "                return None\n",
    "\n",
    "def primary_doc(URL):\n",
    "    \"\"\"\n",
    "    Function: Grab Primary Doc File From Filing Detail Link\n",
    "\n",
    "    Variables\n",
    "        URL: Filing Detail Link\n",
    "    \"\"\"\n",
    "    soup = Request(URL, 'HTML')\n",
    "\n",
    "    doc = Request(f\"https://www.sec.gov{soup.select('.blueRow a')[0]['href']}\", 'XML') # Grab XML data\n",
    "    period_of_report = soup.select(\".formGrouping+ .formGrouping .info\")[0].text # Grab Filing Date and Reporting Date\n",
    "    filing_date = soup.select(\".formGrouping:nth-child(1) .info:nth-child(2)\")[0].text\n",
    "\n",
    "    return doc, period_of_report, filing_date, URL\n",
    "\n",
    "def registrant_info(soup):\n",
    "\n",
    "    \"\"\"\n",
    "    Function: Generate Series Containing Registrant Information\n",
    "\n",
    "    Variables\n",
    "        soup: XML Soup Object\n",
    "    \"\"\"\n",
    "\n",
    "    reg_info = soup.find_all(\"genInfo\")[0].find_all(True) # Grab all Registrant Info from soup object\n",
    "    reg_info_series = pd.Series({tag.name: tag.text for tag in reg_info}) # Format into pandas series\n",
    "\n",
    "    return reg_info_series\n",
    "\n",
    "def investment_info(investment):\n",
    "\n",
    "    \"\"\"\n",
    "    Function: Generate Dictionary Containing Portfolio Restricted Holding Information\n",
    "\n",
    "    Variables\n",
    "        investment: A single 'invstOrSec' portion of XML file\n",
    "    \"\"\"\n",
    "\n",
    "    tags = investment.find_all(True) # Grab all tags from holding\n",
    "    tag_d = {tag.name: tag.text for tag in tags} # Format into a dictionary\n",
    "\n",
    "    if tag_d['isRestrictedSec'] == 'Y': # Only perform code on Restriced Securities\n",
    "        return_d = {}\n",
    "        return_d['Issuer'] = tag_d['name']\n",
    "        return_d['Title'] = tag_d['title']\n",
    "        return_d['Current_Balance'] = float(tag_d['balance'])\n",
    "\n",
    "        if tag_d['valUSD'] != 'N/A':\n",
    "            return_d['Total_Value'] = float(tag_d['valUSD'])\n",
    "        else:\n",
    "            return_d['Total_Value'] = 0\n",
    "\n",
    "        try:\n",
    "            return_d['Asset_Class'] = tag_d['assetCat']\n",
    "        except: \n",
    "            return_d['Asset_Class'] = 'Other'\n",
    "\n",
    "        return_d['Payoff_Profile'] = tag_d['payoffProfile']\n",
    "        return_d['Fair_Value_Level'] = tag_d['fairValLevel']\n",
    "        return_d['Restricted'] = tag_d['isRestrictedSec']\n",
    "\n",
    "        return return_d\n",
    "    \n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def format_df(URL):\n",
    "\n",
    "    \"\"\"\n",
    "    Function:\n",
    "        Format XML of holdings information into DataFrame\n",
    "\n",
    "    Variables\n",
    "        doc: Primary Doc Tuple Output (Contains XML Soup Object, Reporting and Filing Date, and Original URL)\n",
    "    \"\"\"\n",
    "\n",
    "    soup, period_of_report, filing_date, URL = primary_doc(URL)\n",
    "    \n",
    "    col_order = ['Form_Type', 'Company_Name','CIK','Fund_Series','Series_ID','Reporting_Date',\n",
    "                     'Filing_Date','Issuer', 'Title','Valuation','Current_Balance','Total_Value',\n",
    "                     'Asset_Class','Payoff_Profile','Fair_Value_Level','Link','Restricted']\n",
    "    \n",
    "    portfolio_columns = ['Issuer','Title','Current_Balance', 'Total_Value', \n",
    "                         'Asset_Class','Payoff_Profile', 'Fair_Value_Level','Restricted']\n",
    "\n",
    "    reg_info = registrant_info(soup) # Get Registrant Info\n",
    "\n",
    "    investments = [investment_info(investment) for investment in soup.find_all(\"invstOrSec\")] # Get tag information for each restriced holding\n",
    "    \n",
    "    portfolio_d = {column : [] for column in portfolio_columns} # Dictionary to later be turned into a dataframe\n",
    "    \n",
    "    for d in investments: # Loop through each investment\n",
    "        for column in portfolio_columns:\n",
    "            try:\n",
    "                portfolio_d[column].append(d[column]) # If the investment has a tag in portfolio_columns, add it to the dictionary\n",
    "            except:\n",
    "                portfolio_d[column].append(None) # Otherwise, leave this field blank\n",
    "\n",
    "    return_df = pd.DataFrame(portfolio_d).assign(Form_Type = soup.headerData.submissionType.text,\n",
    "                                                 Company_Name = reg_info.regName, # Format into a dataframe and assign Registrant Info\n",
    "                                                 CIK = reg_info.regCik,\n",
    "                                                 Fund_Series = reg_info.seriesName,\n",
    "                                                 Reporting_Date = period_of_report,\n",
    "                                                 Filing_Date = filing_date,\n",
    "                                                 Valuation = lambda df: df['Total_Value']/df['Current_Balance'],\n",
    "                                                 Link = URL)\n",
    "\n",
    "    if 'seriesId' in reg_info:\n",
    "        return_df = return_df.assign(Series_ID = reg_info.seriesId)\n",
    "    else:\n",
    "        return_df = return_df.assign(Series_ID = 'N/A')\n",
    "\n",
    "    return_df = return_df.loc[return_df.Restricted == 'Y',col_order].drop(columns=['Restricted']) # Reorder Columns\n",
    "\n",
    "    return_df['Reporting_Date'] = pd.to_datetime(return_df['Reporting_Date']) # Convert to datetime datatype\n",
    "    return_df['Filing_Date'] = pd.to_datetime(return_df['Filing_Date'])\n",
    "\n",
    "    return return_df\n",
    "\n",
    "def main(URL_List, csv_name, save_csv = False, google_colab = False):\n",
    "\n",
    "    URL_List = tqdm(URL_List, desc=\"Gathering Data\") # Format to show progress bar\n",
    "\n",
    "    final_df = (pd.concat(list(map(format_df, URL_List))) # Loop through each URL and stack outputs\n",
    "                    .sort_values(['Company_Name','Title','Reporting_Date','Fund_Series']) # Reorder Rows\n",
    "                    .reset_index(drop=True))\n",
    "    \n",
    "    if save_csv == True:\n",
    "        final_df.to_csv(f\"{csv_name}.csv\")\n",
    "\n",
    "        if google_colab == True:\n",
    "            from google.colab import files\n",
    "            files.download(f\"{csv_name}.csv\") \n",
    "\n",
    "\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Manual Links\n",
    "\n",
    "'''\n",
    "Instructions for Manual URLs\n",
    "\n",
    "Step 1: Enter each link in quotes as a comma seperated list between brackets \n",
    "  Note: If there is only 1 URL, it still must be surrounded by brackets\n",
    "\n",
    "Step 2: Run this Cell to assign the list of links to the variable URL_list\n",
    "  Note: Do not run the Upload Links Cell. This will override the URL List assigned here\n",
    "\n",
    "Step 3: Run the Main Function Below to gather data from links\n",
    "'''\n",
    "\n",
    "\n",
    "URL_list = ['https://www.sec.gov/Archives/edgar/data/1319067/0001387131-21-001485-index.htm',\n",
    "           'https://www.sec.gov/Archives/edgar/data/1319067/0001387131-21-002834-index.htm',\n",
    "           'https://www.sec.gov/Archives/edgar/data/1319067/0001387131-21-002914-index.htm']\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Upload Links From Spreadsheet\n",
    "\n",
    "'''\n",
    "Step 1: Set ```path``` equal to the file path (in quotations) for the csv file where the links are located.\n",
    "        This will assign the file path to the \"path\" variable\n",
    "  Note: If running in google colab, first upload the csv file by clicking the files\n",
    "        icon on the left side and clicking \"upload to session storage\" icon near the top\n",
    "\n",
    "Step 2: Set ```column_name``` to the name of the column (in quotations) where the \n",
    "        links are located inside the spreadsheet.\n",
    "\n",
    "Step 3: Run this Cell to assign the list of links to the variable URL_list\n",
    "  Note: Do not run the Upload Links Cell. This will override the URL List assigned here\n",
    "\n",
    "Step 4: Run Cell 6 to gather data from links\n",
    "'''\n",
    "\n",
    "\n",
    "path = '2021-2023 NPORT filings.csv'\n",
    "column_name = 'File_Name'\n",
    "\n",
    "csv = pd.read_csv(path)\n",
    "URL_list = csv.loc[150000:,column_name] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'main' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m save_csv \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     13\u001b[0m google_colab \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mmain\u001b[49m(URL_list, csv_name \u001b[38;5;241m=\u001b[39m csv_name, save_csv \u001b[38;5;241m=\u001b[39m save_csv, google_colab \u001b[38;5;241m=\u001b[39m google_colab)\n\u001b[0;32m     17\u001b[0m df\n",
      "\u001b[1;31mNameError\u001b[0m: name 'main' is not defined"
     ]
    }
   ],
   "source": [
    "# Cell 6: Main Function\n",
    "\n",
    "'''\n",
    "Saving as a csv file\n",
    "\n",
    "csv_name: set equal to whatever you would like the resulting csv to be called (in quotations).\n",
    "save_csv: set equal to True (no quotations) to save csv, otherwise set to False (no quotations)\n",
    "google_colab: If using Google Colab, set equal to True (no quotations), otherwise set to False (no quotations)\n",
    "'''\n",
    "\n",
    "csv_name = 'my_csv'\n",
    "save_csv = False\n",
    "google_colab = False\n",
    "\n",
    "df = main(URL_list, csv_name = csv_name, save_csv = save_csv, google_colab = google_colab)\n",
    "\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
